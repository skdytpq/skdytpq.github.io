---
title: 로지스틱
sidebar:
  nav: docs-ko
aside:
  toc: False
categories:
  - 기초통계
key: 20210810
tags: 
  -통계학
use_math: true
---

# logistic이란?
보통 설명변수와 반응변수의 관계를 생각할 때, 선형회귀 알고리즘에 익숙한 우리는 반응변수 $Y$ 를 수치형으로 생각한다.

하지만 만약 출력값인 $Y$가 범주형이라면 우리는 입력값 $X$를 넣어 여러 클래스 중 알맞은 클래스로 $Y$를 분류하는 것을 기대할 것이다.
# 선형회귀에서의 작업
---
단순 선형회귀에서 기존에 우리가 했던 작업은 $y_i = \beta_0 + \beta_1*X_i+ \epsilon_i$라는 회귀식에서 출발한다.

[//]:# (식 1)

위의 식은 기존 모집단의 회귀식 $Y = \beta_0 + \beta_1 * X$ 에서 관측값에 대한 오차 $\epsilon$ 을 추가한 것인데

우리는 이 오차에 대한 가정을 $N(0,\sigma^2)$을 따른다고 하기 때문에 회귀계수 추정을 위한 관측값들의 추정 회귀식에서

기댓값을 취하면 $E[Y_i] = \beta_0 + \beta_1*X_i$가 된다.

한편 여기서 $X_i$들은 상수이므로 (관측값) $Y_i$의 분산역시 $\sigma^2$으로 주어진다.

따라서 $y_i$는 $X=x_i$로 주어질 때 평균이  $\beta_0 + \beta_1*X_i$ 이고 분산이  $\sigma^2$인 **확률변수이다**

그렇다면 이 회귀식에서 적절한 해석은 어떻게 해야하는가?

intercept인 $\beta_0$는 $y=0$일때의 $Y$의 평균값이며 $\beta_1$은 $x_i$ 가 1단위 증가할 때 $E[Y]$의 변화량이다
(***위식에서 X가 범주형 변수인 경우에는 $\beta_1$에 대한 해석은 $X = 0 or 1$일 때 평균값의 차이이다!***)

여기서 우리는 식(1)에서 표본을 통해 회귀식을 추정하고 그 추정값을 검정하는 과정을 거치는데, 그 부분은 차후에 다루겠다.

어쨋든 우리는 단순선형회귀에서 적절한 $\beta$값을 찾기 위한 강력한 idea인 최소제곱법 $\sum_{i=1}^{n} (y-\hat{y_i})^2$을 이용한다.

이 과정을 거친 후의 회귀식은 식(1)과 같이 해석이 굉장히 직관적이며 $\beta_0,\beta_1$로만 이루어진 경우에는 시각적으로도 이해하기 쉽다.

그러나 $y$가 범주형일 때 적절한 회귀 직선을 그어 input의 $x$값으로 $y$를 분류하는 것은 꽤 애매한 작업일 수 있다.

그 이유는 기존 선형회귀처럼 직선을 그으면 주어지는 $X$의 값의 범위 제한이 없다면  $Y$값의 범위는 이론적으로 $(-\infty,\infty)$ 가 되는데

실제 우리의 목적은 $y$의 클래스를 분류하는 것이기때문에 분류를 위한 적절한 $Y$ 값을 찾기 어렵기 때문이다.

<p align = "center">
  <img width = "400" src = "https://raw.githubusercontent.com/angeloyeo/angeloyeo.github.io/master/pics/2020-09-23-logistic_regression/pic2.png">
  <br>
  그림 2. 범주형 데이터에 대해 선형회귀 모델을 적용하는 경우
</p>

위 그림에서 보듯이 $y$가 범주형인 데이터에 선형회귀 모델을 fitting 시킨 후 그래프를 그리니 해석하기가 애매하다.

기준이 되는 $X$ 는 어디인가? 또한 경계값은 어디인가? 를 따질 때 애매한 부분이 한둘이 아니다.

따라서 범주형 데이터에 해석을 진행할 때 좀 더 용이할 수 있게 기존 선형회귀 모델이 아닌 다른 모델을 생각해보는 게 자연스럽다.

그렇기에 데이터를 보는 관점을 조금 뒤집어 보자.

우리는 우선 input 데이터를 조금 변형시킬 것이다.

범주형 데이터에 어울리는 데이터의 형태는 $[0,1]$ 사이에서 매끄럽고 $x$ 가 어떤 값을 넘어가면 출력 결과가 변하는 형태가 좋겠다.

또한 이러한 변화가 불연속적인 것보다 연속적인 S자 커브 형태면 더 좋을 것이다.

이러한 S자 커브 함수의 형태에는 여러가지 후보가 있겠지만 우리는 그중 Sigmoid 함수를 선택했다고 가정하고 진행해보자.
<p align = "center">
    $S(x) = \frac{1}{1+\exp(-x)}$
    <br>
    시그모이드식의 기본형태
</p>
왜 Sigmoid 함수인지는 차후에 깊게 공부한 후 이야기하겠다.

일단 우리는 data를 바라보는 관점을 $X$ 의 변화에 따라 $Y$의 범위를 $(0~1)$ 사이로 한정시키는 것에 성공했다. 

하지만 여기서 앞서 Sigmoid 의 $exp(-x)$ 는 어떻게 해석해야 하는가? 또 여기서의 $Y$ 값은 분명 범주형이라 했는데 왜 연속형인가?
  
로지스틱 회귀분석을 위해 이 $x$ 자리에는 $\beta_0+\beta_1*X$가 들어가는데, 우리가 조절해야하는 prameter인 $\beta$들의 변화는

위의 에서 어떤 영향을 주는지 해석하는 것은 직관적이지 않고 어렵다.

또한 $Y$값은 분명 범주형이라고 했는데 왜 연속형인지에 대해서도 아직까지 의문이다.

우리는 기존에 선형회귀에서 $Y$값을 그저 $X$에 따른 어떤 값이라고 보는 것에 익숙해져있다. 

그러나 지금부터 우리는 $Y$값을 확률(probability)측면에서 바라봐주도록 하자.

우선 $Y$ 값에 대해 $P(Y_i=1)$ 을 $\pi_i$ 이고 $P(Y_i=0)$을 $1-\pi_i$ 라고 해보자.

여기서 $Y_i$값에 기대값은 $$P(Y_i =1)*1 + P(Y_i=0)*0$$ 이므로 $E[Y_i] = \pi$가 된다.

# 승산(odds)에 대하여

따라서 우리는 $\beta$를 해석하기 위해 우선 뜬금없겠지만 승산의 개념에 대해 알아보자.

우선 odds의 의미는 성공확률/실패확률이다. 즉, 결과가 성공과 실패밖에 없다고 가정하고 성공확률을 $p$ 실패확률을 $1-p$라고 할 때

odds는 $\frac{p}{1-p}$ 이다. 이 odds는 $p$가 0에 수렴한다면 $0$로 $p$가 1로 수렴한다면 $\infty$로 발산할 것이다.

이런 승산비가 왜 중요한 것인가?

여기서도 $Y$의 결과는 두 경우밖에 없기 때문에 odds의 개념을 대입한다면 $odds = \frac{\pi(X=x)}{1-\pi(X=x)}$ 로 표현 가능하다.

이 odds에 $log$를 취하면 어떻게 될까? $log(odds)$ 는 $log(\frac{\pi(X=x)}{1-\pi(X=x)})$이 되고 앞서 우리는 

 $\frac{1}{1+\exp(-x)}$ 이 

