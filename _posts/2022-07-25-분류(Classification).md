---
title: 분류(Classification)
sidebar:
  nav: docs-ko
toc: true
toc_sticky: true
categories:
  - 머신러닝
key: 2022-07-25
tags: 
  -머신러닝
use_math: true
---

# 분류(Classification)

### Introduction

머신러닝 & 딥러닝 분야에서 분류는 가장 일반적인 Task 중 하나이다.

객체를 분류한다던지 이미지를 분류한다던지 분류의 종류는 매우 많으며 다양하다고 할 수 있다.

예를 들어 강아지와 고양이를 분류하는 모델을 만든다고 할 때 우리는 단순히 CNN 계열의 모델을 만들어 학습을 시킬 수 있는데, 실제 Task 에서는 보다 다양한 상황이 존재할 수 있다.

아주 위험한 모델 하나를 가정해보자. 

이 모델은 사람의 얼굴만 보고 이 사람이 범죄자인지 아닌지 판단하여 경찰에게 알리는 모델이다.

이 모델의 Issue는 두 가지 이다.

- 일반인으로 판단한 사람 중 범죄자인 경우
- 범죄자라고 판단한 사람 중 일반인인 경우

이 모델은 이 두 가지 Issue 중 두번째가 매우 critical 할 것이다. 

99%의 범죄자가 이 모델을 통해 발각되었다고 하더라도 일반인 중 30%도 이 모델을 통해 범죄자로 판단된다면 아주 도덕적인 문제가 있는 모델이기 때문에 실제 사회에선 나올 수 없을 것이다.

### Trade-off

위 모델의 가정에서 한 가지 의문이 들 수 있다. 

일반인을 범죄자라고 오판하지 않으면서도 범죄자를 확실하게 판단할 수 있는 모델을 만들면 되지 않을까?

하지만 그러한 모델은 존재할 수 없다.

모델에는 임계값(Threshold)라는 것이 있다.

이러한 임계값은 ‘’역치‘’라고 생각할 수 있는데, 예를 들어 몸무게가 70kg이 넘는 사람은 보통체중이라고 정의할 때 70이라는 기준이 임계값이라고 할 수 있다.

이 임계값의 특성은 변화하는 값이라는 것이다.

보통 체중의 정의를 좀 더 일반화 하고 싶을 때 우리는 60kg이라고 임계값을 바꿔버리면 보통 체중의 사람이 더 많아지게 되는 것과 마찬가지로 임계값에 따라서 이전 판단에서 거짓이었던 것이 참이 될 수도 있다.

앞서 가정한 모델도 모델 내부적으로 어떠한 기준이 있을 것이다.

그리고 또한 그 기준을 넘는 사람은 범죄자, 아닌 사람은 일반인 이라고 판단 할 것인데, 이 기준을 $T$라고 하고 이 $T$가 0.5 이상일 때 현재 모델에서는 범죄자 라고 판단한다고 하자.

$A$라는 사람은 0.48로 ‘일반인’ 판정을 받은 범죄자 이고, $B$ 라는 사람은 0.49로 ‘일반인’판정을 받은 일반인 이라고 해보자.

해당 모델이 100%의 범죄자를 잡고 싶다면 어떻게 해야할까? 단순히 $T$라는 임계값을 낮추면 모든 범죄자를 잡을 수 있다.

그렇게 되어 $A$의 경우를 갖는 범죄자도 잡기 위해 $T$를 0.45로 내리게 된다면 $A$라는 사람을 잡을 수는 있겟지만 $B$라는 무고한 일반인도 같이 범죄자로 판단하게 된다.

여기서 $A$라는 사람을 진짜 양성(True Positive: TP) 라고 하며, $B$라는 사람을 가짜 양성(False Positive: FP)라고 한다.

이 TP 의 수를 늘리기 위해 임계값을 낮춘다면 자연스럽게 TP와 비슷하지만 양성이 아닌 FP 도 모델의 True 판단에 포함되게 될 것이다. 

이것과 마찬가지로 FP를 낮추기 위해 임계값을 높인다면 FP는 감소하겠지만 반대로 FN(False Negative: 음성으로 판단했지만 양성인 거짓 음성)의 수가 올라갈 것이다.

이렇게 임계값에 따라 TP와 FP의 관계는 Trade-off이다. 다시말해 하나가 증가하면 덩달아 오르길 원치 않는 하나도 증가하게 되는 것이다. 

따라서 적절한 임계값을 통해 TP와 FP의 분류를 하여 일종의 협상을 진행하는 것이 실제 Task 에서 중요한 요소라고 할 수 있다.

즉 모델을 어떤식으로 바라볼지에 여부라고 할 수 있는데, 모델을 설계하고 잘 작동하는지 판단할 때 우리는 어떤 기준으로 판단할 것인지를 정하는 과정이라고 생각할 수 있다.

### 정밀도 & 재현율

앞서 말한 TP,FP에 대해 좀 더 자세하게 알아보자.

앞서서 TP는 모델의 예측값도 범죄자이고 실제 범죄자인 사람들로 모델이 잘 분류한 경우이다.

FP 는 모델의 예측값은 범죄자이지만 실제 범죄자가 아닌 사람들이다.

우리가 단 모델의 TP 값과 FP 값의 관계를 보기위해 사용하는 것은 정밀도 인데 정밀도는 아래와 같은 수식으로 만들어진다.

- 정밀도  = $\frac{TP}{TP+FP}$ 

이 정밀도의 경우는 앞선 가정과 같은 모델 즉, $FP$를 많이 만드는 것이 위험한 경우 사용하는 척도이다.

모든 사람을 다 범죄자라고 판단한다면 모든 범죄자는 잡는 거지만 그만큼 FP 도 매우 높아져 정밀도로 판단할 경우 해당 모델은 딱히 좋은 성능을 내지 못한다고 생각할 수 있다. 

다른 경우는 어떨까?

예를 들어 어떤 모델은 코로나 확진자를 판단하는 모델이라고 해보자.

해당 모델은 코로나 확진 판정을 받았지만 사실 코로나가 아닌 $FP$ (거짓 양성)의 경우 보다 코로나 음성 판정을 받았지만 코로나가 걸린 $FN$(거짓 음성)의 경우가 더 위험하다.

따라서 우리는 잘못 판단하여 코로나가 아닌 사람도 양성으로 판단하는 경우가 있더라도 모든 코로나 확진자는 확진 판정을 받게 하고자 하는 목적이 있는 모델을 설계해야 한다.

이러한 모델을 설계할 때 사용하는 척도가 재현율이라고 할 수 있는데, 재현율의 경우 아래와 같은 식으로 나오게 된다.

- 재현율 = $\frac{TP}{TP+FN}$

만약 코로나 확진 판정의 기준이 매우 느슨해 진다면 $FN$의 수가 감소하여 전반적은 재현율은 늘어날 수 있다. 

또한 이진분류에서 뿐만 아니라 다중분류와 같은 경우 각 Labeled 데이터의 크기의 차이가 심하다면 각 라벨에서의 정밀도, 재현율의 가중치가 달라져야 하는데, 이러한 경우를 반영한 것이 F1-Score이다.

이 F-1 Score는 정밀도와 재현율의 조화 평균을 낸 것인데, 두가지 모두 고려하는 Score 이기 때문에 좋은 지표 중 하나라고 할 수 있다.

$F_1 = 2\times \frac{정밀도 \times 재현율}{정밀도 + 재현율}$

<p align = "center">
  <img width = "600" src = "https://github.com/skdytpq/skdytpq.github.io/blob/master/_pics/VAE/%EB%B6%84%EB%A5%98_4.png?raw=true">
  <br>
  그림 1.Confusion Matrix
</p> 

해당 그림은 모델의 예측값과 실제값을 비교하여 만든 2진 분류의 Matrix이다. 

재현율과 정밀도는 위 그림에서 잘 판단할 수 있을 것이다.

여기서 우리가 명심해야 할 것은 이 판단의 척도인 재현율 정밀도와 같은 것이 우리가 아는 비용함수와 헷갈리면 안된다는 것이다.

비용함수란 모델링을 할 때 수식적으로 정의하여 해당 모델의 파라미터를 갱신하는 작업을 수행할 때 쓰는 것이라면, 재현율 정밀도와 같은 경우는 우리가 모델을 바라보는 시각이다.

예를 들어 Cross Entropy Loss로 이진분류 모델을 훈련한다고 했을 때 해당 비용 함수는 사용하는 것이 적절하다.

하지만 정밀도, 재현율로 모델을 판단한다는 것은 정의된 Loss 값을 바꾼다는 것이 아니라 저렇게 나온 Loss의 정도를 어떻게 판단할 지 이야기 하는 것이다.

예를 들어 정밀도가 매우 높은 모델을 만들고 싶은 입장에선 Loss로 나온 p = 0.75라는 값은 모델의 확신의 정도가 낮은 수준이라고 생각할 것이고 정밀도보단 재현율을 높게 보고싶은 모델에서는 0.75라는 값을 높은 수준이라고 판단할 수 있다.

따라서 정밀도, 재현율, F1-score와 같은 것은 실제 모델 내부의 파라미터를 갱신한다는 입장이 아닌, 파라미터가 갱신된 모델을 바라보는 관점이라고 판단할 수 있다.

### ROC-AUC

보통의 모델은 임계값에 따라 성능의 변화가 나타나기 때문에 실제 이 모델이 다른 모델과 비교했을 때 좋은지에 대한 객관적인 성능의 척도를 찾기 어렵다.

<p align = "center">
  <img width = "600" src = "https://github.com/skdytpq/skdytpq.github.io/blob/master/_pics/VAE/%EB%B6%84%EB%A5%98_2.png?raw=true">
  <br>
  그림 2.임계값에 따른 TP,FP,TN,FN 변화
</p> 

따라서 임계값에 따라 변화하지 않으면서도 균형이 맞춰진 척도가 필요한데, 이러한 척도를 ROC-AUC라고 할 수 있으며 Kaggle 과 같이 컴페티션이 있다면 종종 ROC-AUC를 척도로 하여 평가를 진행한다.

ROC-AUC는 거짓 양성 비율 대비 진짜 양성 비율 (FPR & TPR)을 사용하는데, 두 축으로 그린 그래프의 면적의 넓이를 구하여 성능을 평가한다.

<p align = "center">
  <img width = "600" src = "https://github.com/skdytpq/skdytpq.github.io/blob/master/_pics/VAE/%EB%B6%84%EB%A5%98_5.webp?raw=true">
  <br>
  그림 3.ROC-AUC
</p> 

해당 그림과 같이 ROC-AUC가 그려지는데, 여기서 x 점들의 위치, 현의 휨 정도를 이해하면 ROC-AUC는 생각보다 쉽게 이해가 될 것이다.

- 현 위 점들의 의미 :
  -  우선 현 위의 점들은 임계값들이라고 할 수 있다. 예를 들어 현 위의 점이 x축 끝단에 가면 [1,1]에 위치하게 되는 것을 알 수 있는데, 이 의미는 임계값이 매우 낮아져 모든 데이터를 다 양성으로 판단한다는 의미이다.
  - 반대로 [0,0]에 위치할 때는 임계값이 매우 높아져 모든 데이터 샘플을 음성으로 처리하는 경우이다. 따라서 현위의 점은 임계값들의 변화에 따른 분류기 성능의 양상을 보여주는 것이라고 할 수 있다.
- 현의 휨 정도의 의미
  - 현의 휨 정도는 분류기의 성능을 의미한다. 그림 2의 경우 두 봉우리가 겹쳐져 있는 부분이 꽤 많다. 하지만 저 두 봉우리가 겹쳐진 부분이 거의 없게 된다면, FP의 비율도 임계값이 증가하여도 별로 높게 나타나지 않을 것이다.
  - 이 것과 마찬가지로 만약 어떤 분류기가 TN 과 TP의 봉우리를 확실하게 분류한다면 보통의 임계값에서 TPR의 비율이 압도적으로 높게 될 것인데, 이 비율이 높다는 것은 현이 왼쪽 상단으로 많이 휘게 될 것이라는 이야기이다.
  - 따라서 왼쪽 상단으로 많이 올라온 커브일 수록 분류기의 성능이 좋다고 할 수 있으며, 자연스럽게 현이 감싸고 있는 면적 값인 AUC 값도 높게 나타날 것이다.