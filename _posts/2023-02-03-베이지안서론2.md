---
title: 베이지안 서론2
sidebar:
  nav: docs-ko
toc: true
toc_sticky: true
categories:
  - 딥러닝
key: 20230203
tags: 
  - 딥러닝
use_math: true
---

# 베이지안 서론2

## Intro

지난 게시글에서 얘기한 것은 베이지안 통계의 기본이 되는 아이디어에 대한 것이었다.

다시한번 복기하자면 베이지안 통계란, 수집된 데이터를 통해 알 수 없는 분포를 추정하는 것이었다.

$P(\theta \vert X) \propto \pi(\theta)P(X\vert \theta) $  의 식으로 표현될 수 있다.(베이지안 정리)

실제 세계에서 어떤 사건은 우리가 알지 못하는 특정 분포에서 나올 수 있다. 예를 들어 아침에 일어나서 아침으로 계란 프라이를 먹기 위해 계란을 까는 순간 쌍란이 나왔다고 했을 때, 이 경우는 계란 중 쌍란이 있을 분포에서 나온 특정 사건이라 할 수 있으며 해당 확률은 $P(X \vert \theta)$ 라고 할 수 있다.

만약 우리가 실제 계란을 엄청나게 많이 깨트려서 쌍란이 나올 확률 분포를 추정하고 싶다면 어떻게 모델링 할 수 있을까?

앞선 베이지안 정리를 이 상황에 대입한다고 하면 아래와 같이 해석할 수 있다.

- $\pi(\theta)$ : 우리가 알지 못하는 쌍란이 나올 분포(**$\theta$ 에 대한 분포이기 때문에 이산 확률이 아닌 연속 확률에 대한 분포이다!**)(사전 분포)

  - 이 부분이 개인적으로 공부하면서 가장 헷갈렸던 부분이다. 

    실질적으로 베이지안 정리를 사용하기 위해 우리는 두개 이상의 분포를 곱해가며 사후 분포를 추정하게 되는데, 이렇게 사건이 0과 1로 되어있는 이산 확률 분포를 따른다고 해서 $\theta$ 자체는 이산 확률이 아니다. 

    $\theta ^{a} (1-\theta)^{n-a}$  와 같은 이항 분포에서 $\theta$ 가 가질 수 있는 확률은 0~1 사이의 연속 값이기 때문이다. 

    따라서 $\theta$에 대한 추정은 Beta분포, Truncated normal 분포 등 연속 확률 분포로 가정하는 것이 바람직하다.(물론 모델링 하려는 상황에 따라 이산 확률 분포가 될 수도 있음)

-  $P(X\vert \theta)$ : 실제 우리가 관찰한 쌍란이 나온 경우(우도 함수)

  - 우리는 실제 $\theta$ 를 모르기 때문에 단순하게 식을 설계하기만 하면 된다. 위 경우에서 우리는 쌍란이거나 아니거나 두 경우중 하나기 때문에 이항 분포를 사용하는 것이 바람직 해 보인다.

    따라서 $\theta^{D}(1-\theta)^{N-D}$ (D는 쌍란이 나올 확률) 분포에서 나오는 사건이라고 생각하는 것이 합당할 것 같다.

- $P(\theta \vert X)$ : 우리가 만든 두가지 분포를 통해 나온 확률 분포(사후 분포)

  - $\theta$ 를 예측하는 것이기 때문에 연속 확률 분포이다.
  - 만약 $\pi(\theta)$ 를 Beta 분포라고 가정한다면, 켤레 함수이기 때문에(나중에 소개하겠습니다) 해당 사후 분포는 Beta 분포를 따르게 된다.

우리는 총 세가지 분포를 결정하게 됐다. 이제 여기서 우리에게 필요한 것은 단순히 데이터를 관찰하고 $P(X\vert \theta)$ 를 견고하게 만들면 된다. 

그렇게 된다면 $\theta$에 대한 사후 분포가 나오게 되며, 해당 분포를 우리는 실제 데이터 관찰 결과를 이용하여 얻게 된 쌍란이 나올 분포라고 생각할 수 있다.

## 사전정보가 있는 동전 던지기

지난 게시글에 이어 동전 던지기 예시를 다른 관점으로 접근해자.

이번에는 저번과 다르게 동전이 나올 사전 분포가 0~1 사이의 Uniform 분포가 아닌, 0.5 근처에 있을 것이라는 사전 정보가 있다고 생각해보자.

- $\pi(\theta) \sim Beta(2,2)$
- $p(y|\theta) \propto \theta^y (1-\theta)^{n-y}$ 
- $p(\theta|y) \propto \theta^{y+1} (1-\theta)^{n-y+1} \propto Beta(y+2, n-y+2) $
    - $Beta$ 로 사전 분포를 가정한다면 사후 확률 $P(y\vert \theta)$ 도 $Beta$가 되어 계산이 용이하다.

해당 가정을 모델링 하기 위해 Python 코드는 다음과 같다.

```python
n_trial = 2
np.random.seed(seed=0) # random seed 고정
data = stats.bernoulli.rvs(0.5, size=n_trial) # Bernoulli(0.5)에서 random number 추출
# 사전 분포를 정의했기 때문에 사후 분포가 1에 대해 예측하지 않음
x = np.linspace(0, 1, 100)
heads = data.sum() # 앞면의 개수 
y = dist.pdf(x, 2 + heads, 2 + n_trial - heads) # theta 를 정의한 후의 결과값
# 데이터를 사용하여 posterior density 계산 

plt.plot(x, y, label="observe %d tosses,\n %d heads" % (n_trial, heads))
plt.fill_between(x, 0, y, color="#348ABD", alpha=0.4)
plt.vlines(0.5, 0, 4, color="k", linestyles="--", lw=1)
plt.xlabel("$p$, probability of heads") 
plt.show()
```

<p align = "center">
  <img width = "400" src = "https://github.com/skdytpq/skdytpq.github.io/blob/master/_pics/bayse/bayse2/pic3.png?raw=true">
  <br>
  그림 1
</p>

데이터도 분명 앞선 게시글에서 가정했듯 2번 시행 시 모두 앞면이 나온 데이터를 활용했지만, 위 그림처럼 결과가 극단적으로 치어져져 있지 않음을 확인할 수 있다.

이 이유는 우리가 사전 분포를 0.5를 기점으로 종 모양을 이루는 Beta(2,2) 를 사용했기 때문이다. 

이렇게 사전 분포에 대한 근거있는 정보가 있으면 해당 정보를 모델링하여 사전분포로 집어넣게 된다면 극단적인 데이터가 들어오더라도 어느정도 사전 분포로 가정한 우리의 믿음에 부합한 사후분포가 업데이트 될 수 있다.

그러나 만약 데이터가 엄청나게 많이 들어오게 된다면 사전 분포를 극단적으로 이상하게 가정하지 않는 이상 어느정도 사후 분포 업데이트 시 사전 분포의 영향력을 낮출 수 있다.

<p align = "center">
  <img width = "600" src = "https://github.com/skdytpq/skdytpq.github.io/blob/master/_pics/bayse/bayse2/pic4.png?raw=true">
  <br>
  그림 2
</p>

위 그림은 사전 분포를 uniform 분포로 가정하고 사후 분포를 시행 횟수에 맞게 업데이트 한 그림이다. 

그림을 보면 시행횟수가 점점 많아질수록 아무리 unifrom 분포로 사전분포를 가정했다고 하더라도  0.5 근처에서 $\theta$ 가 분포하는 결과를 확인할 수 있다.

이것만 보면 사후 분포를 구하는 것은 매우 쉬운 작업일 것이라 생각할 수 있는데, 상황이 복잡하다면 이렇게 모델링을 하는 것이 어려울 수 있다. 

좀 더 어려운 상황을 가정해보자.

## 상황가정 : 문자 메시지 데이터

- **어느 사용자가 매일 주고받은 문자 메세지를 수집하여 매일 수신한 문자 메세지 개수를 기록하였다. 이 데이터를 바탕으로 사용자의 메세지 습관이 시간의 흐름에 따라 서서히 변하는지 갑자기 급변하는지 알고 싶다.**

<p align = "center">
  <img width = "600" src = "https://github.com/skdytpq/skdytpq.github.io/blob/master/_pics/bayse/bayse2/pic5.png?raw=true">
  <br>
  그림 3
</p>

위와 같이 일 별 메시지 분포가 이루어져 있다고 해보자.

우선 우리는 하루에 문자가 몇통이 오는지에 대한 분포를 모델링 하는 것이 필요할 것이다.

해당 분포는 앞선 베이지안 정리의 식에서 $P(X\vert\theta)$ 에 해당한다. 따라서 실제 주어진 데이터를 어떤 분포를 통해서 나온 결과 값이라고 생각하자는 것이다.

그렇기 위해 분포 $C_i : i$ 일의 문자 개수 $C_i \sim Poi(\lambda)$ 라고 해보자. $Poi$ 는 포아송 분포로써, 단위 구간 당 시행 횟수에 대한 분포를 모델링 할 수 있다.

또한 여기서 $\lambda$ 는 해당 분포의 평균으로 작용하는데, 문제의 가정에서 어느 순간 급변하는지를 알고 싶다고 했기 때문에 특정 순간에서 $\lambda$ 값은 변할 것이다.

만약 문자 수가 변하는 구간이 한 지점(예를 들어 10일차)이라면 $\lambda_a , \lambda_b$ 는 10일차 전 후로 문자 수를 결정하는 파라미터로 작용할 것이다.

따라서 변환점을 $\tau$라고 하고 $\lambda$ 값을 설정해보자.  
$$\lambda = \left\{
\begin{matrix}
\lambda_1 & \mbox{if } t<\tau\\
\lambda_2 & \mbox{if } t\geq\tau\\
\end{matrix}
\right. $$  

우리는 여기서 $\tau$라는 파라미터를 추가적으로 모델링 하였다.

우리가 예측하는 파라미터를 한번 다시 정리하자면 우선 $\lambda, \tau$ 값이다. 또한 해당 값에서 파생되는 $C_i$ 값 또한 모델링이 필요하다.

그렇다면 우리의 사전분포는 $\lambda$ 에 대한 사전분포로 설정하는 것이 합당할 것이다. 그 이유는 우리에게 주어진 데이터는 우선 포아송 분포에서 나온 것이라고 가정하였으며 그렇다면 $P(X \vert \lambda)$ 는 $Poi(\lambda_{\tau_1})$ 분포라고 할 수 있다.

우리는 또한 $\lambda$ 에 대한 사전 분포를 만들어야 한다.

$\lambda$의 사전확률분포를 지수분포로 설정 

$$\begin{align}
&\lambda_1 \sim \text{Exp}( \alpha ) \\\
&\lambda_2 \sim \text{Exp}( \alpha )
\end{align}$$

지수 분포로 설정 한 이유는 임의의 양수값을 가지는 각 $\lambda$에 대한 분포로 적당하다고 판단했기 때문이다.

여기서 또 미지의 모수 $\alpha$ 가 등장하게 되는데, 여기서 $\alpha$까지 분포로 모델링을 하는 것은 우리의 주된 관심사가 아니기 때문에 $\alpha$ 값은 데이터에서 직접 확인 가능한 평균 문자 수의 역수가 되도록 세팅을 하겠다.

그 이유는 포아송 분포의 평균이 $\frac{1}{\alpha}$ 이기 때문이다.

또한 우리는 $\lambda_1, \lambda_2$ 를 구분하기 위한 파라미터 $\tau$를 모델링 해야 하는데, 여기서는 단순하게 1~70 사이의 양수를 임의로 추출할 수 있는 Discrete unifrom 분포를 따르도록 설정을 하겠다.

$\begin{align}
& \tau \sim \text{DiscreteUniform(1,70) }\\\\
& \Rightarrow P( \tau = k ) = \frac{1}{70}
\end{align}$

따라서 우리는 총 세개의 분포(포아송, 지수, 유니폼)을 설정하였는데 해당 분포를 통해 사후분포를 직접 구하는 것은 상당히 고된 작업이 될 수 있다.

따라서 Python 의 모듈은 Pymc를 사용하여 실제 사후 분포를 모델링 해보자.

```python
# !pip install pymc3

# 모델을 구성
import pymc3 as pm
import theano.tensor as tt
# count_data : 문자 메시지 데이터
with pm.Model() as model:
    alpha = 1.0/count_data.mean()  # Recall count_data is the
                                   # variable that holds our txt counts
    lambda_1 = pm.Exponential("lambda_1", alpha)
    lambda_2 = pm.Exponential("lambda_2", alpha)
    tau = pm.DiscreteUniform("tau", lower=0, upper=n_count_data - 1)

with model:
    idx = np.arange(n_count_data) # Index
    lambda_ = pm.math.switch(tau > idx, lambda_1, lambda_2)
    # lambda_ 는 1과 2 중 idx tau 를 기준으로 바뀐다
    # Lambda 의 경우 사전 분포 Exponential 에서 나오며 Tau 라는 조건에 따라 달라지기 때문에 경우가 두 개
with model:
    observation = pm.Poisson("obs", lambda_, observed=count_data)
    #각각 샘플링을 진행. lambda 와 data를 그 람다에서 나온 분포라고 가정한다.
    # 여기서 data는 사전에 가정한 분포에서 나온 것이라고 취급한다.
    # Observation 은 우리가 예측한 사전 분포에서 Sampling 된 Lambda 값에서 나오는 것.(우도함수)
    
### 모델에서 랜덤샘플을 추출
with model:
    step = pm.Metropolis()
    trace = pm.sample(10000, tune=5000,step=step)
```

해당 과정은  Markov Chain Monte Carlo(MCMC) 방법으로 **확률변수** 𝜏,𝜆 의 값을 추출하여 추론한다. 해당 방법론은 차후 게시글에서 이야기 하겠다.

이와 같은 과정을 샘플링이라고 하는데, 직관적으로 앞서 가정한 분포에 맞는 값들을 계속해서 샘플링을 한 이후 그 샘플링 결과를 누적하여 추정된 분포가 어떤 모양인지 대략적으로 보여주는 것이라고 할 수 있다.

실질적으로 여러 분포가 곱해지거나 더해지면 분포가 굉장히 모호해지기 때문에 어떠한 방정식 형태로 결정되기가 매우 어렵기 때문에(적분이 불가능 한 경우가 많다.) 이렇게 분포를 샘플링을 통해 추정하는 경우가 많다.

코드에서 obervation 에 대해 좀 더 살펴보자면, lamba_ 라는 변수는 우리가 모델링을 통해 얻게 된 **사전분포** lambda_ 값이며 count_data 는 실제 문자 데이터라고 할 수 있다.

해당 과정에서 count_data 는 사전 분포와 함께 계산되는 우도함수 라고 할 수 있다.

앞선 동전 던지기 예시와 비교하여 조금 복잡해 진 것 같지만 앞서 베이지안 식에 대입하면 해당 과정이 그리 복잡하지 않은 것을 알 수 있다.

$P(\theta \vert X) \propto \pi(\theta)P(X\vert \theta) $  

위 식에서 $\theta = \lambda$라고 할 때, 앞선 식에서 바뀐 점은 $\pi(\theta) $ 가 $\tau$ 의 분포에 따라 바뀌는 조건부 확률로 변한 것 밖에 없다.

$\pi(\theta) = \pi(\theta \vert \tau)$ 라고 할 수 있으며 우리는 $\tau$에 대한 분포와 $\theta$ 에 대한 분포를 이미 설정 해 놓았기 때문에 계산이 가능하다.(샘플링이 가능하다.)

위와 같이 trace 변수에서처럼 10000번 샘플링을 진행하게 되면 샘플링을 통해 얻은 결과값을 토대로 우리가 설정한 각 파라미터의 사후분포 $\lambda, \tau$ 를 추정할 수 있다.

아래의 그림은 해당 샘플링 결과를 토대로 분포를 시각화 한 것이다. 

해당 그림을 보면 약 44~45 일차를 기점으로 문자 메세지의 평균이 약 18을 따르는 포아송 분포에서 약 23을 따르는 포아송 분포에서 추출되는 것을 알 수 있다.

<p align = "center">
  <img width = "600" src = "https://github.com/skdytpq/skdytpq.github.io/blob/master/_pics/bayse/bayse2/picc6.png?raw=true">
  <br>
  그림 4
</p>

모델링 한 과정이 매우 헷갈리는 것이 당연하지만, 우리가 추정하고자 하는 것은 포아송 분포가 아니라 그 분포를 만들게 된 **$\lambda$** 값임을 기억하자. 

**또한 우리가 기존에 갖고있던 메시지 데이터는 해당 $\lambda$ 값을 통해 가정한 포아송 분포에서 얻은 것이라는 상황을 기억하자** 

베이지안 모델링을 좀 더 복잡하게 진행할 경우, 내가 무엇을 하는지, 예측하는 것이 대체 무엇인지, 어떤 변수를 모델링 하는 것인지, 이게 연속형인지 이산형인지, 이게 확률변수인지 등이 매우 어려울 것이다.

나는 이렇게 개념들이 헷갈리는 것이 당연한 것이라고 생각한다. 하지만 좀 더 깊게 공부하고 이해하다 보면 내가 무엇을 하고 있는 것인지에 대한 방향은 잡을 수 있을 거라고 생각한다.

